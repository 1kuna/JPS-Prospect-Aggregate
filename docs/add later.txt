celery/redis
pydantic?
loguru (if truly necessary)
tailwind
router!!
RHF/Zod
docker

dashboard toasts


LLM enrichment of data
    - add missing naics codes
    - infer more naics codes for better search/filtering
        - try to stay within the 4-digit parent for inferring when one is already present UNLESS it's generic
    - mark all inferred data with blue text (like tesla autopilot blue)
    - let users filter between original and inferred included
    - status on the advanced page and start/stop button for LLM enrichment

marking opportunities as go/no-go
    - potentially showing who logged such and when they did for queued manual verification

BUG FIXES, FEATURES, & QUESTIONS:

- how does the batch ai enhancement work? shouldn't it go 1 by 1 for each listing instead of batching for higher accuracy?
    - instead of selecting how many to do in batch, shouldn't there just be a "start/stop" button that just makes it iteratively add to each listing 1-by-1?
- should remove the demo listings in the ai enhancement "Recent Activity" section
    - real enhancement runs don't appear in the "Recent Activity" section
- in the database tab of the advanced page, there should be the option to clear only the ai entries, only the original entries, and all the entries as separate options.
- time works properly on literally every page of the site besides the "data sources" tab, where it consistently is showing 4 hours ahead of when it should. can you not just replace that time logic with logic from any other part of the site so it works properly?
- the ai enrichment filter on the dashboard page doesn't actually do anything it seems. all results show no matter what is selected
- the "clear all" button on the filter panel should be greyed out and unclickable when there are no filter options entered/selected

- when data sources are pulled/refreshed, is there a safety mechanism to prevent overwriting and duplication? i don't want my listings overwritten if i've already done AI processing on them because that defeats the purpose. but on the other hand, if they update it with new useful information that is more accurate than the LLM version, i think that could be useful as well.